<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>A Newborn Embodied Turing Test for Visual Parsing &mdash; NETT 0.4.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/custom_styles.css?v=2fd9c8d7" />

  
    <link rel="canonical" href="/html/3papers/Parsing.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=c87aa342"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="A Newborn Embodied Turing Test for View-Invariant Recognition" href="ViewInvariant.html" />
    <link rel="prev" title="Research Papers" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            NETT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../1gettingstarted/index.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2documentation/index.html">Documentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Research Papers</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">A Newborn Embodied Turing Test for Visual Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="ViewInvariant.html">A Newborn Embodied Turing Test for View-Invariant Recognition</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NETT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Research Papers</a></li>
      <li class="breadcrumb-item active">A Newborn Embodied Turing Test for Visual Parsing</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/3papers/Parsing.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="a-newborn-embodied-turing-test-for-visual-parsing">
<h1>A Newborn Embodied Turing Test for Visual Parsing<a class="headerlink" href="#a-newborn-embodied-turing-test-for-visual-parsing" title="Link to this heading"></a></h1>
<p>Manju Garimella, Denizhan Pak, Lalit Pandey, Justin N. Wood, &amp; Samantha M. W. Wood</p>
<video controls>
   <source src="../_static/video/parsing.mp4" type="video/mp4">
</video>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h2>
<p><em>Newborn brains exhibit remarkable abilities in rapid and generative learning, including the ability to parse objects from backgrounds and recognize those objects across substantial changes to their appearance (i.e., novel backgrounds and novel viewing angles). How can we build machines that can learn as efficiently as newborns? To accurately compare biological and artificial intelligence, researchers need to provide machines with the same training data that an organism has experienced since birth. Here, we present an experimental benchmark that enables researchers to raise artificial agents in the same controlled-rearing environments as newborn chicks. First, we raised newborn chicks in controlled environments with visual access to only a single object on a single background and tested their ability to recognize their object across novel viewing conditions. Then, we performed “digital twin” experiments in which we reared a variety of artificial neural networks in virtual environments that mimicked the rearing conditions of the chicks and measured whether they exhibited the same object recognition behavior as the newborn chicks. We found that biological chicks developed background-invariant object recognition, while the artificial chicks developed background-dependent recognition. Our benchmark exposes the limitations of current unsupervised and supervised algorithms in achieving the learning abilities of newborn animals. Ultimately, we anticipate that this approach will contribute to the development of AI systems that can learn with the same efficiency as newborn animals.</em></p>
</section>
<section id="experiment-design">
<h2>Experiment Design<a class="headerlink" href="#experiment-design" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>VR chambers were equipped with two display walls (LCD monitors) for displaying object stimuli.</p></li>
<li><p>During the Training Phase, artificial chicks were reared in an environment containing a single 3D object rotating a full 360° around a horizontal axis in front of a naturalistic background scene. The object made a full rotation every 15s.</p></li>
<li><p>During the Test Phase, the VR chambers measured the artificial chicks’ imprinting response and object recognition performance. The “imprinting trials” measured whether the chicks developed an imprinting response.  The “test trials” measured the aritifical chicks’ ability to visually parse and recognize their imprinted object. During these trials, the imprinted object was presented on one display wall and an unfamiliar object was presented on the other display wall. Across the test trials, the objects were presented on all possible combinations of the three background scenes (Background 1 vs.Background 1, Background 1 vs. Background 2, Background 1 vs.Background 3, etc.).</p></li>
</ul>
</section>
<section id="arguments">
<h2>Arguments<a class="headerlink" href="#arguments" title="Link to this heading"></a></h2>
<section id="train-configuration">
<h3>Train configuration<a class="headerlink" href="#train-configuration" title="Link to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent_count</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">run_id</span><span class="p">:</span><span class="n">exp1</span>
<span class="n">log_path</span><span class="p">:</span> <span class="n">data</span><span class="o">/</span><span class="n">exp1</span>
<span class="n">mode</span><span class="p">:</span> <span class="n">full</span>
<span class="n">train_eps</span><span class="p">:</span> <span class="mi">1000</span>
<span class="n">test_eps</span><span class="p">:</span> <span class="mi">40</span>
<span class="n">cuda</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">Agent</span><span class="p">:</span>
  <span class="n">reward</span><span class="p">:</span> <span class="n">supervised</span>
  <span class="n">encoder</span><span class="p">:</span> <span class="n">small</span>
<span class="n">Environment</span><span class="p">:</span>
  <span class="n">use_ship</span><span class="p">:</span> <span class="n">true</span>
  <span class="n">side_view</span><span class="p">:</span> <span class="n">false</span>
  <span class="n">background</span><span class="p">:</span> <span class="n">A</span>
  <span class="n">base_port</span><span class="p">:</span> <span class="mi">5100</span>
  <span class="n">env_path</span><span class="p">:</span> <span class="n">data</span><span class="o">/</span><span class="n">executables</span><span class="o">/</span><span class="n">parsing_benchmark</span><span class="o">/</span><span class="n">parsing</span><span class="o">.</span><span class="n">x86_64</span>
  <span class="n">log_path</span><span class="p">:</span> <span class="n">data</span><span class="o">/</span><span class="n">ship_backgroundA_exp</span><span class="o">/</span><span class="n">Env_Logs</span>
  <span class="n">rec_path</span><span class="p">:</span> <span class="n">data</span><span class="o">/</span><span class="n">ship_backgroundA_exp</span><span class="o">/</span><span class="n">Recordings</span><span class="o">/</span>
  <span class="n">record_chamber</span><span class="p">:</span> <span class="n">false</span>
  <span class="n">record_agent</span><span class="p">:</span> <span class="n">false</span>
  <span class="n">recording_frames</span><span class="p">:</span> <span class="mi">0</span>
</pre></div>
</div>
<section id="run-script">
<h4>Run script<a class="headerlink" href="#run-script" title="Link to this heading"></a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>src/simulation/run_parsing_exp.py<span class="w"> </span>++run_id<span class="o">=</span>exp1<span class="w"> </span>++Environment.env_path<span class="o">=</span>data/executables/parsing_benchmark/parsing_app.x86_64<span class="w"> </span>++mode<span class="o">=</span>full<span class="w"> </span>++train_eps<span class="o">=</span><span class="m">1000</span><span class="w"> </span>++test_eps<span class="o">=</span><span class="m">40</span><span class="w"> </span>++Agent.encoder<span class="o">=</span><span class="s2">&quot;small&quot;</span><span class="w"> </span>++Environment.use_ship<span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="w"> </span>++Environment.background<span class="o">=</span><span class="s2">&quot;A&quot;</span>
</pre></div>
</div>
<p>where</p>
<p><code class="docutils literal notranslate"><span class="pre">Environment.use_ship</span></code> = True or False (to choose between Ship and Fork);
<code class="docutils literal notranslate"><span class="pre">Environment.background</span></code> = A, B, C (to choose between the three background);
mode = full or train or test (to choose between the three modes to run);
<code class="docutils literal notranslate"><span class="pre">Agent.encoder</span></code> = “small”, “medium” or “large” to choose between the three different types of encoders: NatureCNN, resnet10 and resnet18
<code class="docutils literal notranslate"><span class="pre">Agent.reward</span></code> = “supervised” default</p>
</section>
<section id="custom-configuration">
<h4>Custom Configuration:<a class="headerlink" href="#custom-configuration" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p>Update train episode count; test episode count</p></li>
<li><p>Encoder types - small, medium and large</p></li>
<li><p>Reward types - supervised or ‘unsupervised’</p></li>
</ul>
</section>
</section>
</section>
<section id="links">
<h2>Links<a class="headerlink" href="#links" title="Link to this heading"></a></h2>
<p><a class="reference external" href="https://origins.luddy.indiana.edu/unity/executables/">Executables can be found here</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Research Papers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ViewInvariant.html" class="btn btn-neutral float-right" title="A Newborn Embodied Turing Test for View-Invariant Recognition" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Zachary Laborde.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>