{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from nett import Brain, Body, Environment\n",
    "from nett import NETT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "An encoder is part of the Brain component, and generates a feature representation (embedding) for the incoming observations. Specifically, for each set of observations, the encoder consumes them to produce an N-dimensional vector that is passed on to the `Policy` Network to produce a prediction (the action that the body will take). \n",
    "\n",
    "![title](/home/desabh/netts-tutorials/Encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, the encoder can be anything as long as it can take the observation set produced from the environment and produce an embedding vector. \n",
    "\n",
    "![title](/home/desabh/netts-tutorials/Encoder-Detail.png)\n",
    "\n",
    "In the following notebook, we will define a custom encoder which is a `Convolutional Neural Network` (CNN) that produces an embedding vector of `256`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from gym import spaces\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom Encoder MUST inherit from the `BaseFeaturesExtractor` class from `stable_baselines3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "\n",
    "        self.linear = torch.nn.Sequential(torch.nn.Linear(n_flatten, features_dim), torch.nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define components (brain, body and environment)\n",
    "# this example shows only a minimal setup, a LOT of customization is possible here\n",
    "brain = Brain(encoder=CustomCNN, train_encoder=True)\n",
    "body = Body(type=\"basic\", dvs=False)\n",
    "environment = Environment(config=\"parsing\", executable_path=\"/home/desabh/builds/parsing/parsing-linux.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the NETT\n",
    "nett = NETT(brain=brain, body=body, environment=environment)\n",
    "# run the NETT\n",
    "jobs = nett.run(dir=\"./parsing_testrun\", num_brains=5, train_eps=1000, test_eps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nett.analyze(run_dir=\"./parsing_testrun\", output_dir=\"./analysis_results\", ep_bucket=100, num_episodes=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
